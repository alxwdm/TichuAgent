{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainAgents.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNqrtiOaaQCjEgWERwPKKH9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fjkm2DIq0Tr",
        "colab_type": "text"
      },
      "source": [
        "# TichuAgents: Training the Agents\n",
        "\n",
        "This notebook is used for training Agents using Reinforcement Learning to play Tichu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrOs1k1rrC_I",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf0KUdu0qw2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Execute after restarting runtime\n",
        "!git clone https://github.com/alxwdm/tichuagent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gf7HZOaZrFWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Execute when content on github changed\n",
        "%cd /content/tichuagent\n",
        "!git pull\n",
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHWZ41PPrF1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "sys.path.append('/content/tichuagent')\n",
        "# import Environment\n",
        "from env.env import Env\n",
        "# import all Agents\n",
        "from agents.heuristic.greedy import greedyAgent\n",
        "from agents.ddpg.ddpg_agent import DDPGAgent\n",
        "# import utility functions\n",
        "from utils import play_dumb_game, play_greedy_game"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEkCOuERsE67",
        "colab_type": "text"
      },
      "source": [
        "# Shared utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfjJAP0SsGTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def battle(agents, n_games=1000):\n",
        "    \"\"\" Lets trained agents play games against each other. \"\"\"\n",
        "    pass # TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TbB0VCcrS1P",
        "colab_type": "text"
      },
      "source": [
        "# DDPG Agent\n",
        "\n",
        "Deep Deterministic Policy Gradient is an off-policy RL approach that combines both value- and policy-based learning. The DDPG actor learns how to act (i.e. policy-based), and a critic learns how to estimate the current situation (i.e. value-based). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WI9cMP4nr87n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ddpg(n_episodes=100, episode_offset=0, checkpoint_path=None,\n",
        "         eps_start = 0.3, eps_decay = 0.995, max_steps = 1000):\n",
        "    \"\"\" Trains a DDPG Agent on Tichu. \"\"\"\n",
        "    # initialize environment and agent\n",
        "    env = Env(train_mode=True)\n",
        "    state_size, action_size = env.info()\n",
        "    heuristic_agent = greedyAgent()\n",
        "    agent = DDPGAgent(state_size=state_size, action_size=action_size,\n",
        "                  random_seed=0, heuristic_agent=heuristic_agent)\n",
        "    all_scores = []\n",
        "    eps = eps_start\n",
        "    # reload checkpoint from previous training if available\n",
        "    if checkpoint_path:\n",
        "        agent.load_checkpoint(filepath=checkpoint_path)\n",
        "    # train for n_episodes\n",
        "    for i_episode in range(episode_offset, n_episodes + episode_offset):\n",
        "        state, reward, done, active_player = env.reset()\n",
        "        action_buffer = [None, None, None, None]\n",
        "        scores = [0, 0, 0, 0]\n",
        "        nstep = 0\n",
        "        init_cnt = 0\n",
        "        # make a valid initial move from heuristic agent (first steps)\n",
        "        # each player must make an initial move before learning,\n",
        "        # because of reward-design (reward is valid every 4 steps)\n",
        "        idle_cnt = 0\n",
        "        while any(elem is None for elem in action_buffer):\n",
        "            action_buffer[active_player] = agent.act(state[active_player], 1)\n",
        "            state, reward, done, active_player = env.step(active_player,\n",
        "                                            action_buffer[active_player])            \n",
        "            idle_cnt += 1\n",
        "            if idle_cnt > 10:\n",
        "                raise EnvironmentError(\"Something went wrong.\")\n",
        "                #return state[active_player]\n",
        "        # train one episode\n",
        "        while nstep < max_steps:\n",
        "            prev_state = state\n",
        "            # regular learning routine after initialization:\n",
        "            # learn from previous step, then take next step\n",
        "            # vice-versa not possible (because of state/reward validity)\n",
        "            agent.step(prev_state[active_player],\n",
        "                       action_buffer[active_player],\n",
        "                       reward[active_player],\n",
        "                       state[active_player],\n",
        "                       done, nstep)\n",
        "            # add rewards to scores list\n",
        "            scores[active_player] += reward[active_player]\n",
        "            # take an action in the environment\n",
        "            prev_state[active_player] = state[active_player]\n",
        "            action_buffer[active_player] = agent.act(state[active_player], eps)\n",
        "            state, reward, done, active_player = env.step(active_player,\n",
        "                                                  action_buffer[active_player])\n",
        "            nstep += 1\n",
        "            # all agents take a step when game is finished\n",
        "            if done:\n",
        "                for i in range(4):\n",
        "                    agent.step(prev_state[i], action_buffer[i],\n",
        "                               reward[i], state[i], done, nstep)\n",
        "                break\n",
        "        # print episode info\n",
        "        print('\\rEpisode: {} \\t Steps: {} \\t Avg score: {}'.format(i_episode,\n",
        "                                                    nstep, np.mean(scores)),\n",
        "              end='')\n",
        "        if i_episode > 0 and i_episode%10 == 0:\n",
        "            print('')\n",
        "        # take average rewards of all agents\n",
        "        all_scores.append(np.mean(scores))\n",
        "        eps = eps_decay * eps # decrease epsilon\n",
        "    # save checkpoints\n",
        "    fpath = 'checkpoint_' + str(i_episode)\n",
        "    agent.save_checkpoint(filename=fpath)\n",
        "    return all_scores"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzo9V5JMh7yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_scores = ddpg(eps_decay=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhRkP7LdiHBE",
        "colab_type": "text"
      },
      "source": [
        "# Debugging Area"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd2jfwhDh_nY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for debugging, use this function to nicely print action vector as cards:\n",
        "# example: _vec_to_cards(action).show()\n",
        "def _vec_to_cards(vec):\n",
        "    \"\"\" Turns a vector representation into a Cards instance. \"\"\"\n",
        "    all_cards = Deck().all_cards\n",
        "    return Cards(list(compress(all_cards, vec)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}